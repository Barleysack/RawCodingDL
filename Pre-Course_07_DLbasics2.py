#이산형 확률 변수는 확률 변수가 가질 수 있는 경우의 수를 모두 고려하여 확률을 더해서 모델링. 
#연속형 확률 변수는 데이터 공간에 정의된 확률변수의 밀도 위에서의 적분을 통해 모델링한다.  밀도는 확률로 해석하는게 아니다. 

#데이터 공간을 X x Y 로 표기하고 D는 데이터 공간에서 데이터를 추출하는 분포이다. 
#데이터는 확률변수로 (x,y) ~ D로 표기.
#결합 분포 P(x,y)는 D를 모델링합니다. 
#D는 이론적으로 존재하는 확률분포이기 때문에 사전에 알 수 없습니다 .
#주변확률분포: 결합확률 분포를 각각의 Y에 대해 더하거나 X에 대해 적분 해서 유도해낸다. 
#조건부 확률 P(y|x)는 입력변수 x에 대해 정답이 y일 확률을 의미. 

#로지스틱 회귀에서 사용된 선형모델과 소프트맥스 함수의 결합은 데이터에서 추출된 패턴을 기반으로 확률을 해석하는데 사용된다. 
#분류 문제에서 softmax(WO+b)은 데이터 X로부터 추출된 특징패턴 o(x)과 가중치행렬 W를 통해 조건부 확률 P(y|x)를 계산한다..
#회귀 문제의 경우 조건부 기댓값 E[y|x]을 추정한다.
#l2노름을 최소화하는 함수 f(x)와 조건부기댓값이 동일해진다...(연속확률의 경우...)
#딥러닝은 다층 신경망을 사용해 데이터로부터 특징패턴 phi를 추출해낸다. 
#기계학습의 많은 문제들은 확률분포를 명시적으로 모른다. 
#확률분포를 모를때 데이터를 이용해 기댓값을 계산하려면 몬테카를로 샘플링 방법을 사용해야 한다. 
#샘플링을 독립적으로 해줘야한다는데.. 몬테카를로 샘플링이 뭔지 설명을 왜...?


import numpy as np

def mcsamp(f,l,h,ssize=100,rep=10):
    length = np.abs(h-l)
    stat = []
    for _ in range(rep):
        x = np.random.uniform(low=l,high=h,size=ssize)
        f_x = f(x)
        int_val = length*np.mean(f_x)
        stat.append(int_val)
    return np.mean(stat), np.std(stat)
def f__x(x):
    return np.exp(-x**2)

print(mcsamp(f__x,l=-1,h=1,ssize=10000,rep=100))
#애초에 몬테카를로 방법이 무엇인가? 

