{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pre-Course_09_Pytorch_TensorManipulation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOHDJEdrO7H9bjfKgNVbVG6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Barleysack/RawCodingDL/blob/main/Pre_Course_09_Pytorch_TensorManipulation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYAOLtP5yz3Y"
      },
      "source": [
        "import numpy as np\n",
        "import torch as tch"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qa_WF2vyzU8B"
      },
      "source": [
        "#텐서 |t|는 배치사이즈와 차원을 곱한 값을 크기로 가진다. \n",
        "#파이토치는 첫번째 차원의 값이 세로값, 두번째 차원 값이 가로값, 세번째 차원 값이 깊이를 뜻한다. \n",
        "#하나의 관습. 기본적으로는 이러한 형태를 따른다. \n",
        "#NLP의 경우에도... 배치사이즈 * 길이* 디멘션\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-JVZPrJzWS0"
      },
      "source": [
        "t=np.array(np.arange(10))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlHT29241XFQ",
        "outputId": "d21cd1db-a6ef-4003-faf7-da898e294baf"
      },
      "source": [
        " print(t)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 2 3 4 5 6 7 8 9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ir4yO7QD1X_z",
        "outputId": "c045d3ae-a859-4418-d5b0-5923c11d2a6b"
      },
      "source": [
        "print(t.ndim)\n",
        "print(t.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "(10,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOVbKog51pN8",
        "outputId": "6768f614-88a3-4b72-c1d3-740c3f403bc3"
      },
      "source": [
        "print(t[0])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YeGSQzvj2FNf",
        "outputId": "514cc9a3-0e0b-4c43-e386-004afa244095"
      },
      "source": [
        "k= np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
        "print(k)\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 2 3]\n",
            " [4 5 6]\n",
            " [7 8 9]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fxYNz5-2T-2",
        "outputId": "b4a3fb6d-1c2d-4e20-ec45-008a6766fae2"
      },
      "source": [
        " a = torch.FloatTensor([0,2,3,4,5,5,6,6,7])\n",
        " print(a)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0., 2., 3., 4., 5., 5., 6., 6., 7.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxTClMiW3B3b",
        "outputId": "68551425-c86c-410f-f5bd-35c9e40afb80"
      },
      "source": [
        "a.dim #뭐 np쪽이랑 비슷한거 다 잘 나오는 것을 알 수 있다. "
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function Tensor.dim>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NZwv0Ax3Fzd",
        "outputId": "8b15c6f8-0e06-49a9-b0c9-a59a17f495a5"
      },
      "source": [
        "a1 = torch.FloatTensor([[3,3]])\n",
        "a2 = torch.FloatTensor([[2],[1]])\n",
        "a1+a2"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[5., 5.],\n",
              "        [4., 4.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cm7c1nWL4BU-",
        "outputId": "4d694526-d55f-4599-bc32-1ec78764296f"
      },
      "source": [
        "a1*a2\n",
        "#Broadcasting이 가능하다는 것을 확인할 수 있다. \n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[6., 6.],\n",
              "        [3., 3.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0nL8If04HYB",
        "outputId": "85892be5-32b3-4904-97ed-1d8b3401920c"
      },
      "source": [
        "t = torch.FloatTensor([[1,2],[3,4]])\n",
        "t.mean(dim=0) #dim 0을 없애겠어라고 이해하자.\n",
        "#sum 또한 비슷하다고 보자.\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2., 3.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1hGd2in8En_",
        "outputId": "808a0fa8-ff6c-404a-c5c1-e9285b5adc5c"
      },
      "source": [
        "t.max()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBTaI-r-8nmU",
        "outputId": "468b8d40-3ac9-430f-a6fd-402a31aacaa7"
      },
      "source": [
        "t.argmax()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDXrjHRV8opI",
        "outputId": "69049155-0d47-4e0f-f9de-79b04724b879"
      },
      "source": [
        "#view():reshape와 비스무리하다. \n",
        "t.view([-1,4]) #안의 숫자 곱이 기존 텐서 원소 곱과 같으면 문제 읎다. 위에건 2x2였지?"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2., 3., 4.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFebLpKuFq3w",
        "outputId": "adfa1daa-be4b-4c7f-89e1-5cbc795eade3"
      },
      "source": [
        "t.squeeze() #알아서 엘리먼트가 한개인 디멘션은 날아간다. "
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2.],\n",
              "        [3., 4.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWarnlseHCq6",
        "outputId": "c17155bf-4dd7-44d4-9b1c-6de41c5d0290"
      },
      "source": [
        "t = torch.FloatTensor([[1,2,3,4]])\n",
        "ts=t.squeeze()\n",
        "print(ts.ndim)\n",
        "print(ts.unsqueeze(0))\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "tensor([[1., 2., 3., 4.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTcDfIYGHpi7",
        "outputId": "f6245ceb-70a5-4bd4-8293-149f4f945436"
      },
      "source": [
        "#unsqueeze : 내가 원하는 dimension에 1을 넣어준다. \n",
        "tc= torch.LongTensor([1,2,3,4])\n",
        "print(tc.float())"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1., 2., 3., 4.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGExZ-DYJkqE"
      },
      "source": [
        "bt = torch.ByteTensor([True,1,0,0])"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vD-SIFiqJpQp",
        "outputId": "957df46c-ea3e-4f8c-9cfd-6f343a3caf3c"
      },
      "source": [
        "print(bt.long())"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1, 1, 0, 0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TuH2wCuxJq_w",
        "outputId": "3cdd5e03-905a-44c7-f6bd-caef3ed52745"
      },
      "source": [
        "torch.cat([tc,bt],dim=0)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3, 4, 1, 1, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adPYOeRSKdHw",
        "outputId": "e55d33be-2f4f-4162-cf85-e3c06fd92c7a"
      },
      "source": [
        "ctt=torch.cat([tc,bt],dim=0)\n",
        "ctt.unsqueeze((1))#앞쪽에 디멘션상 1을 추가한다고 생각하면 양호할듯.\n"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1],\n",
              "        [2],\n",
              "        [3],\n",
              "        [4],\n",
              "        [1],\n",
              "        [1],\n",
              "        [0],\n",
              "        [0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OH1oVCSTKftq",
        "outputId": "ee1c4ad4-6a11-4cd8-9d91-0aea84147398"
      },
      "source": [
        "#stacking. cat보다 편리\n",
        "#stack 할 텐서 사이즈가 모두 같을때..\n",
        "torch.stack([tc,bt])"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3, 4],\n",
              "        [1, 1, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb2UHxbUMocl",
        "outputId": "e31db420-a6c9-4838-9d2a-74e729349fa8"
      },
      "source": [
        "pt = torch.FloatTensor([[1,2,3,4,5,5,6,12,125,125,1,25,12,51,2]])\n",
        "\n",
        "print(torch.ones_like(pt))\n",
        "print(torch.zeros_like(pt)) #device 적으로 같은 device여야 텐서 연산이 가능하다. "
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWOBbE0JN-ho",
        "outputId": "996b2b29-324f-4234-acc0-ac671de6eee1"
      },
      "source": [
        "#다중gpu 또는 cpu와 gpu간 연산 등이 그렇다.. \n",
        "#In place Ops : 기존의 연산은 메모리에 새로 선언하나, 인플레이스는 그렇지 않다.\n",
        "\n",
        "print(pt.mul(2.))\n",
        "#이제 이 뒤에 언더바를 넣으면 메모리에 새로 선언하지 않고 결과값을 현 메모리 주소에 넣는다.\n",
        "print(pt)\n",
        "pt.mul_(2.)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[  2.,   4.,   6.,   8.,  10.,  10.,  12.,  24., 250., 250.,   2.,  50.,\n",
            "          24., 102.,   4.]])\n",
            "tensor([[  1.,   2.,   3.,   4.,   5.,   5.,   6.,  12., 125., 125.,   1.,  25.,\n",
            "          12.,  51.,   2.]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  2.,   4.,   6.,   8.,  10.,  10.,  12.,  24., 250., 250.,   2.,  50.,\n",
              "          24., 102.,   4.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kwdfq0M6RXIr",
        "outputId": "d27204b8-58b0-4ab8-981c-b830482d4ecd"
      },
      "source": [
        "\n",
        "print(pt)\n",
        "#inplace 연산은 속도 면에서 빠르지 않을까...?\n",
        "#하지만 파이토치에서 이미 가비지 컬렉터가 잘 수행되기 때문에 좋다. \n"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[  2.,   4.,   6.,   8.,  10.,  10.,  12.,  24., 250., 250.,   2.,  50.,\n",
            "          24., 102.,   4.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zliZUE5SRmWc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}